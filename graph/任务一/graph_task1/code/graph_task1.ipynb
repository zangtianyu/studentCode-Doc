{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "\n",
    "# 定义网络结构\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(GCN,self).__init__()\n",
    "        self.GCN1 = GCNConv(num_features, 16) # hidden=16, (输入的节点特征，中间隐藏层的维度)\n",
    "        self.GCN2 = GCNConv(16, num_classes)    # （中间隐藏层的维度，节点类别)\n",
    "        self.dropout = torch.nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # 加载节点特征和邻接关系\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        # 传入卷积层\n",
    "        x = self.GCN1(x, edge_index)\n",
    "        x = F.relu(x)  # ReLU激活函数\n",
    "        x = self.dropout(x)  #dropout层,防止过拟合\n",
    "        x = self.GCN2(x, edge_index)  # 第二个卷积层\n",
    "        #将经过两层卷积层得到的特征输入log_softmax函数得到概率分布\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAT模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(GAT,self).__init__()\n",
    "        self.GAT1 = GATConv(num_features, 8, heads = 8, concat = True, dropout = 0.6)\n",
    "        self.GAT2 = GATConv(8*8, num_classes, dropout = 0.6)  \n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        x = self.GAT1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.GAT2(x, edge_index)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphSAGE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import SAGEConv\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_features, hidden_dim, num_classes):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.sage1 = SAGEConv(num_features, hidden_dim)  # 定义两层GraphSAGE层\n",
    "        self.sage2 = SAGEConv(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.sage1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.sage2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GIN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GINConv, global_add_pool\n",
    "from torch.nn import Sequential, Linear, ReLU\n",
    "\n",
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GIN, self).__init__()\n",
    "        self.conv1 = GINConv(Sequential(Linear(in_channels, 64), ReLU(), Linear(64, 64)))\n",
    "        self.conv2 = GINConv(Sequential(Linear(64, 64), ReLU(), Linear(64, out_channels)))\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data,device):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "    loss_function = torch.nn.CrossEntropyLoss().to(device)\n",
    "    model.train()\n",
    "    num_epochs = epochs\n",
    "    for epoch in range(num_epochs): # 200 epochs\n",
    "        out_d= model(data)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(out_d[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print('Epoch {:03d} loss {:.4f}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data):\n",
    "    model.eval()\n",
    "    _, pred = model(data).max(dim=1)\n",
    "    correct = int(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "    acc = correct / int(data.test_mask.sum())\n",
    "    print( 'Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def show_time():\n",
    "    t0 = time.time()\n",
    "    r = 0\n",
    "    for i in range(10000000):\n",
    "        r += i\n",
    "    time.sleep(2)\n",
    "    # print(r)\n",
    "    t1 = time.time()\n",
    "    spend1 = t1 - t0\n",
    "\n",
    "    # print(\"-------------------------------\")\n",
    "    print(\"运行时间：{}s\".format(spend1))\n",
    "    print(\"测试完毕\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pickle\nimport torch\nimport numpy as np\nfrom torch_geometric.data import Data\nfrom torch_geometric.transforms import NormalizeFeatures\nfrom torch_geometric.loader import NeighborSampler\n\ndef load_local_planetoid_dataset(name, root='../dataset', transform=None):\n    \"\"\"\n    加载本地Planetoid数据集（CiteSeer, Cora, Flickr）\n    \"\"\"\n    # 加载本地pkl文件\n    data_dict = pickle.load(open(f'{root}/{name}/{name.lower()}.pkl', 'rb'))\n    \n    print(f\"Loading {name} dataset from local file:\")\n    print(f\"  Nodes: {data_dict['topo'].shape[0]}\")\n    print(f\"  Edges: {data_dict['topo'].nnz}\")\n    print(f\"  Features: {data_dict['attr'].shape[1]}\")\n    print(f\"  Classes: {len(np.unique(data_dict['label']))}\")\n    \n    # 转换为torch tensors\n    edge_index = torch.tensor(np.array(data_dict['topo'].nonzero()), dtype=torch.long)\n    x = torch.tensor(data_dict['attr'].toarray(), dtype=torch.float)\n    y = torch.tensor(data_dict['label'], dtype=torch.long)\n    \n    # 创建PyTorch Geometric Data对象\n    data = Data(x=x, edge_index=edge_index, y=y)\n    \n    # 应用变换\n    if transform:\n        data = transform(data)\n    \n    # 创建一个简单的Dataset类来模拟Planetoid接口\n    class LocalPlanetoidDataset:\n        def __init__(self, data):\n            self.data = data\n            self.num_features = data.x.size(1)\n            self.num_classes = data.y.unique().size(0)\n            self.num_node_features = data.x.size(1)\n            \n        def __len__(self):\n            return 1\n            \n        def __getitem__(self, idx):\n            return self.data\n    \n    return LocalPlanetoidDataset(data)\n\n# 加载Cora数据集（默认）\ndataset = load_local_planetoid_dataset('Cora', transform=NormalizeFeatures())\n\n# 加载CiteSeer数据集\n# dataset = load_local_planetoid_dataset('CiteSeer', transform=NormalizeFeatures())\n\n# 加载Flickr数据集\n# dataset = load_local_planetoid_dataset('Flickr', transform=NormalizeFeatures())\n\ndata = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid, Flickr\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch_geometric.loader import NeighborSampler\n",
    "\n",
    "# 加载Cora数据集\n",
    "dataset = Planetoid(root='./dataset', name=\"Cora\", transform=NormalizeFeatures())\n",
    "\n",
    "\n",
    "# 加载CiteSeer数据集\n",
    "# dataset = Planetoid(root='./dataset', name=\"CiteSeer\", transform=NormalizeFeatures())\n",
    "\n",
    "\n",
    "# 加载Flickr数据集\n",
    "# dataset = Flickr(root='./dataset/Flickr')   \n",
    "\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "lr = 1e-3\n",
    "weight_decay = 5e-3\n",
    "momentum = 0.5\n",
    "hidden_dim = 128\n",
    "output_dim = 7\n",
    "num_features = dataset.num_features\n",
    "num_classes = dataset.num_classes\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = GCN(num_features,num_classes).to(device)\n",
    "# model = GAT(num_features, num_classes).to(device)\n",
    "model =GraphSAGE(num_features, hidden_dim,num_classes).to(device)\n",
    "#model = GIN(num_features, num_classes).to(device)\n",
    "train(model, data, device)\n",
    "test(model, data)\n",
    "show_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampler采样\n",
    "print(\"Sampler采样:.................\")\n",
    "train_loader = NeighborSampler(data.edge_index, sizes=[25, 10], batch_size=64, shuffle=True)\n",
    "model = GCN(num_features, num_classes).to(device)\n",
    "def train_with_sampling(model, data, train_loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_size, n_id, adjs in train_loader:\n",
    "        # adjs 是 [(edge_index, e_id, size), ...] 的形式，其中每个 edge_index 是 [2, num_messages] 的格式\n",
    "        adjs = [adj.to(device) for adj in adjs]\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 通过 n_id[:batch_size] 选择原始的中心节点\n",
    "        out = model(data.x[n_id].to(device), adjs[0].edge_index)\n",
    "        \n",
    "        # 只使用中心节点对应的输出进行损失计算\n",
    "        loss = F.nll_loss(out[:batch_size], data.y[n_id[:batch_size]].to(device))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * batch_size\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN(dataset.num_node_features, dataset.num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "# 子图采样训练\n",
    "for epoch in range(1, 201):\n",
    "    loss = train_with_sampling(model, data, train_loader, optimizer, device)\n",
    "    if epoch % 10 == 0:\n",
    "        accuracy = test(model, data, device)\n",
    "        print(f'(Subgraph Sampling) Epoch: {epoch:03d}, Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}