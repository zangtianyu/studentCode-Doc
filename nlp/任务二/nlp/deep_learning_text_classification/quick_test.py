#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯•è„šæœ¬ - éªŒè¯ç³»ç»Ÿæ˜¯å¦èƒ½æ­£å¸¸å·¥ä½œ
"""

import os
import sys
import torch

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_imports():
    """æµ‹è¯•å¯¼å…¥"""
    print("1. æµ‹è¯•å¯¼å…¥...")
    
    try:
        from config import *
        print("  âœ“ é…ç½®å¯¼å…¥æˆåŠŸ")
    except Exception as e:
        print(f"  âœ— é…ç½®å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        from utils.text_processor import TextProcessor
        print("  âœ“ æ–‡æœ¬å¤„ç†å™¨å¯¼å…¥æˆåŠŸ")
    except Exception as e:
        print(f"  âœ— æ–‡æœ¬å¤„ç†å™¨å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        from utils.vocabulary import Vocabulary
        print("  âœ“ è¯æ±‡è¡¨å¯¼å…¥æˆåŠŸ")
    except Exception as e:
        print(f"  âœ— è¯æ±‡è¡¨å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        from models.cnn_model import CNNTextClassifier
        print("  âœ“ CNNæ¨¡åž‹å¯¼å…¥æˆåŠŸ")
    except Exception as e:
        print(f"  âœ— CNNæ¨¡åž‹å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    return True

def test_text_processing():
    """æµ‹è¯•æ–‡æœ¬å¤„ç†"""
    print("2. æµ‹è¯•æ–‡æœ¬å¤„ç†...")
    
    try:
        from utils.text_processor import TextProcessor
        
        processor = TextProcessor()
        
        # æµ‹è¯•æ–‡æœ¬å¤„ç†
        test_text = "This is a test sentence with some words!"
        tokens = processor.process_text(test_text)
        
        print(f"  åŽŸå§‹æ–‡æœ¬: {test_text}")
        print(f"  å¤„ç†ç»“æžœ: {tokens}")
        print("  âœ“ æ–‡æœ¬å¤„ç†æˆåŠŸ")
        
        return True
        
    except Exception as e:
        print(f"  âœ— æ–‡æœ¬å¤„ç†å¤±è´¥: {e}")
        return False

def test_vocabulary():
    """æµ‹è¯•è¯æ±‡è¡¨"""
    print("3. æµ‹è¯•è¯æ±‡è¡¨...")
    
    try:
        from utils.vocabulary import Vocabulary
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_texts = [
            ["this", "is", "a", "test"],
            ["another", "test", "sentence"],
            ["vocabulary", "test", "example"]
        ]
        
        # æž„å»ºè¯æ±‡è¡¨
        vocab = Vocabulary(max_size=100, min_freq=1)
        vocab.build_from_texts(test_texts)
        
        print(f"  è¯æ±‡è¡¨å¤§å°: {len(vocab)}")
        print(f"  æµ‹è¯•ç¼–ç : {vocab.encode(['this', 'is', 'unknown'])}")
        print("  âœ“ è¯æ±‡è¡¨æµ‹è¯•æˆåŠŸ")
        
        return True
        
    except Exception as e:
        print(f"  âœ— è¯æ±‡è¡¨æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_model_creation():
    """æµ‹è¯•æ¨¡åž‹åˆ›å»º"""
    print("4. æµ‹è¯•æ¨¡åž‹åˆ›å»º...")
    
    try:
        from models.cnn_model import CNNTextClassifier
        
        # åˆ›å»ºå°æ¨¡åž‹è¿›è¡Œæµ‹è¯•
        model = CNNTextClassifier(
            vocab_size=100,
            embedding_dim=50,
            num_classes=2,
            num_filters=8,
            filter_sizes=[2, 3],
            dropout=0.1
        )
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        test_input = torch.randint(0, 100, (2, 10))  # æ‰¹æ¬¡å¤§å°2ï¼Œåºåˆ—é•¿åº¦10
        output = model(test_input)
        
        print(f"  æ¨¡åž‹è¾“å‡ºå½¢çŠ¶: {output.shape}")
        print(f"  æ¨¡åž‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
        print("  âœ“ æ¨¡åž‹åˆ›å»ºå’Œå‰å‘ä¼ æ’­æˆåŠŸ")
        
        return True
        
    except Exception as e:
        print(f"  âœ— æ¨¡åž‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_data_loading():
    """æµ‹è¯•æ•°æ®åŠ è½½"""
    print("5. æµ‹è¯•æ•°æ®åŠ è½½...")
    
    try:
        from data.data_loader import DataLoader
        from utils.text_processor import TextProcessor
        
        # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        train_path = "../data/train.tsv/train.tsv"
        if not os.path.exists(train_path):
            print(f"  âš  æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {train_path}")
            print("  è·³è¿‡æ•°æ®åŠ è½½æµ‹è¯•")
            return True
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        text_processor = TextProcessor()
        data_loader = DataLoader(
            data_dir="../data",
            train_file="train.tsv/train.tsv",
            test_file="test.tsv/test.tsv",
            text_processor=text_processor
        )
        
        # åŠ è½½å°‘é‡æ•°æ®è¿›è¡Œæµ‹è¯•
        texts, labels, _, _ = data_loader.load_data()
        
        print(f"  åŠ è½½æ•°æ®æ•°é‡: {len(texts)}")
        print(f"  æ ‡ç­¾åˆ†å¸ƒ: {set(labels)}")
        print("  âœ“ æ•°æ®åŠ è½½æˆåŠŸ")
        
        return True
        
    except Exception as e:
        print(f"  âœ— æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("æ·±åº¦å­¦ä¹ æ–‡æœ¬åˆ†ç±»ç³»ç»Ÿ - å¿«é€Ÿæµ‹è¯•")
    print("=" * 50)
    
    tests = [
        test_imports,
        test_text_processing,
        test_vocabulary,
        test_model_creation,
        test_data_loading
    ]
    
    passed = 0
    total = len(tests)
    
    for test_func in tests:
        try:
            if test_func():
                passed += 1
                print("  âœ“ é€šè¿‡\n")
            else:
                print("  âœ— å¤±è´¥\n")
        except Exception as e:
            print(f"  âœ— å¼‚å¸¸: {e}\n")
    
    print("=" * 50)
    print(f"æµ‹è¯•ç»“æžœ: {passed}/{total} é€šè¿‡")
    
    if passed >= 4:  # è‡³å°‘4ä¸ªæµ‹è¯•é€šè¿‡
        print("ðŸŽ‰ ç³»ç»ŸåŸºæœ¬åŠŸèƒ½æ­£å¸¸ï¼")
        print("\nå»ºè®®çš„è¿è¡Œå‘½ä»¤:")
        print("# è®­ç»ƒCNNæ¨¡åž‹ (5ä¸ªepochå¿«é€Ÿæµ‹è¯•)")
        print("python main.py --model cnn --embedding random --epochs 5")
        print("\n# å¦‚æžœä¸Šé¢æˆåŠŸï¼Œå¯ä»¥å°è¯•å®Œæ•´è®­ç»ƒ")
        print("python main.py --model cnn --embedding random --epochs 20")
    else:
        print("âš ï¸ ç³»ç»Ÿå­˜åœ¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥çŽ¯å¢ƒé…ç½®")
    
    return passed >= 4

if __name__ == "__main__":
    main()
